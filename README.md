# VeritasNet ğŸ§ ğŸ”  
*AI-Powered Multi-Modal Bias Detection System*

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)](https://huggingface.co/transformers/)
[![Streamlit](https://img.shields.io/badge/UI-Built%20with%20Streamlit-orange)](https://streamlit.io/)

---

## ğŸ§  Overview

**VeritasNet** is an advanced AI system for detecting **narrative bias**, **sentiment**, and **framing** in multi-modal content â€” including raw text, transcripts, and YouTube videos.  
It uses fine-tuned transformer models to classify narratives as **Biased** or **Neutral** and provides **explanations** via **Captum**.

---

## ğŸš€ Features

- ğŸ” Binary classification: **Biased vs Neutral**
- ğŸ§  **Explainable AI** with token-level attribution via Captum
- ğŸ¯ Support for:
  - âœï¸ Raw text
  - ğŸ“º YouTube transcripts
  - ğŸ“„ Long-form chunked analysis
- ğŸ“Š Outputs:
  - Bias classification
  - Sentiment detection
  - Framing category
- ğŸŒ Interactive **Streamlit dashboard**

---

## ğŸ—‚ï¸ Project Structure

VeritasNet/
â”œâ”€â”€ app/
â”‚ â””â”€â”€ dashboard.py # Streamlit frontend
â”œâ”€â”€ src/
â”‚ â””â”€â”€ narrative_bias/
â”‚ â”œâ”€â”€ predict.py # Orchestrates full analysis
â”‚ â”œâ”€â”€ preprocess.py # Text cleaning + chunking
â”‚ â”œâ”€â”€ preprocess_expanded.py# Cleans scraped dataset
â”‚ â”œâ”€â”€ video_transcriber.py # YouTube transcript downloader
â”‚ â”œâ”€â”€ label_assistant.py # Semi-auto labeling helper
â”‚ â”œâ”€â”€ train.py # Model training (optional)
â”‚ â””â”€â”€ models/ # Tokenizer/config files (weights excluded)
â”œâ”€â”€ requirements.txt # Required packages
â””â”€â”€ README.md # Project documentation

---

## ğŸ› ï¸ Setup Instructions

### ğŸ§° Requirements

- Python 3.10+
- Git

### ğŸ“¦ Install Dependencies

pip install -r requirements.txt

---

### ğŸ’» Run the Streamlit App

streamlit run app/dashboard.py


- Supports text input or YouTube URLs
- Visualizes bias predictions, framing, sentiment, and token attribution
- Handles long-form transcripts via chunking

---

## ğŸ“š Model Details

| Task              | Model                     |
|-------------------|---------------------------|
| Bias Detection    | BERT / RoBERTa (fine-tuned) |
| Sentiment         | DistilBERT (pretrained)   |
| Framing Detection | Custom BERT fine-tuned    |
| Explainability    | Captum (Integrated Gradients) |

> Models are trained on labeled real-world narratives using custom bias + framing tags.

---

## ğŸ§ª Sample Prediction

### Input:

The corrupt regime has blatantly ignored the needs of the poor.


### Output:
- **Bias:** ğŸŸ¥ Likely Biased  
- **Sentiment:** Negative  
- **Framing:** Political / Class-Based  
- **Attribution:** Highlights â€œcorruptâ€, â€œignoredâ€, â€œpoorâ€

---

## ğŸ§¼ Git Hygiene

This repo uses a `.gitignore` to exclude:

- âœ… Large model files (`*.pt`, `*.safetensors`, `*.bin`)
- âœ… Raw datasets (`.csv`, `.json`)
- âœ… Checkpoints, logs, and HTML explanations
- âœ… Downloaded videos & transcripts

To use this project fully, youâ€™ll need to load your own trained weights, or host them externally (e.g., Hugging Face).

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Credits

- ğŸ¤— Hugging Face Transformers  
- ğŸ“Š Captum for Explainability  
- ğŸŒ Streamlit for UI  
- ğŸ¥ YouTubeTranscriptAPI  
- ğŸ”¥ PyTorch

---

## ğŸ’¬ Contact

For questions or collaboration:  
ğŸ“§ chiragkapoor1009@gmail.com  
GitHub: [@Chikap1009](https://github.com/Chikap1009)